{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:44.046495Z",
     "start_time": "2025-05-02T23:00:44.041296Z"
    }
   },
   "source": [
    "import os, chromadb, google.generativeai as genai, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.config import Settings"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:44.063239Z",
     "start_time": "2025-05-02T23:00:44.058308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "COLL_NAME = 'StackOverflowQnA'\n",
    "CHROMA_PATH = '../lab5/chroma_db'\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "LLM_NAME = 'gemini-2.0-flash'\n",
    "SYSTEM_MSG = ('You are Stack Overflow Assistant. '\n",
    "              'You answer questions based on the knowledge snippets provided. ')\n",
    "with open('key.txt', 'r') as f:\n",
    "    GOOGLE_API_KEY = f.read().strip()"
   ],
   "id": "405635d5de114b7b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:47.853215Z",
     "start_time": "2025-05-02T23:00:44.071419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_PATH, settings=Settings(anonymized_telemetry=False))\n",
    "col = client.get_collection(COLL_NAME)\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "gemini = genai.GenerativeModel(LLM_NAME)"
   ],
   "id": "a9cb4cc3c23dd5fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:50.692139Z",
     "start_time": "2025-05-02T23:00:47.863563Z"
    }
   },
   "cell_type": "code",
   "source": "print('Vectors in Chroma:', col.count())",
   "id": "8d02499e0a529fdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors in Chroma: 1264216\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:50.764675Z",
     "start_time": "2025-05-02T23:00:50.762188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def semantic_search(query: str, k: int = 5):\n",
    "    q_emb = model.encode([query], normalize_embeddings=True)[0]\n",
    "    res = col.query(query_embeddings=[q_emb.tolist()], n_results=k, include=['distances', 'metadatas'])\n",
    "    hits = []\n",
    "    for dist, meta in zip(res['distances'][0], res['metadatas'][0]):\n",
    "        hits.append({'answer': meta.get('answer', ''), 'score': 1 - dist, 'title': meta.get('title', '')})\n",
    "    return hits"
   ],
   "id": "2bf9e7595a257e0c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:50.836596Z",
     "start_time": "2025-05-02T23:00:50.787976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Тестируем\n",
    "for h in semantic_search('How to convert a string to a list in Python?', k=1):\n",
    "    print(f\"Title:  {h['title']}\\nAnswer: {h['answer']}\\nScore:  {h['score']:.3f}\\n\")"
   ],
   "id": "fff9749eb98c5fe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Assign part of a string to a variable [Python]\n",
      "Answer: easy python fun object actually string list safely convert list\n",
      "Score:  0.770\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:50.844387Z",
     "start_time": "2025-05-02T23:00:50.842042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_prompt(user_q: str, ctx: list[dict]) -> str:\n",
    "    parts = [f'User question:\\n{user_q}\\n',\n",
    "             'Knowledge snippets:']\n",
    "\n",
    "    for i, s in enumerate(ctx, 1):\n",
    "        txt = (s['answer'][:500] + '…') if len(s['answer']) > 500 else s['answer']\n",
    "        parts.append(f'[{i}] {txt}')\n",
    "    parts.append('\\nCompose a concise, correct answer citing the snippets.')\n",
    "    return '\\n\\n'.join(parts)"
   ],
   "id": "40c07025188014b3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:00:50.860820Z",
     "start_time": "2025-05-02T23:00:50.858589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rag(user_q: str, k_ctx: int = 3, temperature: float = 0.2):\n",
    "    ctx = semantic_search(user_q, k_ctx)\n",
    "    user_prompt = make_prompt(user_q, ctx)\n",
    "    # Скомбинируем системное сообщение и пользовательский запрос для моделей, которые не поддерживают системную роль\n",
    "    full_prompt = f'{SYSTEM_MSG}\\n\\n{user_prompt}'\n",
    "    resp = gemini.generate_content(\n",
    "        [{'role': 'user', 'parts': [full_prompt]}],\n",
    "        generation_config={'temperature': temperature, 'max_output_tokens': 512}\n",
    "    )\n",
    "    return resp.text, ctx"
   ],
   "id": "451bd59a0f4ed0af",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T23:40:18.329787Z",
     "start_time": "2025-05-02T23:40:14.461541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tests = [\n",
    "    'How to convert string to int in Python?',\n",
    "    'Как создать commit в Git, если нет изменений?'\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    answer, ctx = rag(q)\n",
    "    print('?', q)\n",
    "    for i, doc in enumerate(ctx, 1):\n",
    "        answer_snippet = (doc['answer'][:70] + '...') if len(doc['answer']) > 70 else doc['answer']\n",
    "        print(f\"  [ctx{i}] → {answer_snippet}  (score {doc['score']:.3f})\")\n",
    "    print('! Ответ Gemini:\\n', answer, '\\n' + '-' * 100 + '\\n')"
   ],
   "id": "27c65401af7f249a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? How to convert string to int in Python?\n",
      "  [ctx1] → would recommend use try catch also use module  (score 0.730)\n",
      "  [ctx2] → easy way first convert sure fractional part always zero faster would u...  (score 0.715)\n",
      "  [ctx3] → return python always return string convert result integer explicitly d...  (score 0.685)\n",
      "! Ответ Gemini:\n",
      " To convert a string to an integer in Python, you can explicitly convert the result to an integer [3]. It's also recommended to use a try-except block for error handling [1]. If you're sure the fractional part is always zero, converting to a float first might be faster [2].\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "? Как создать commit в Git, если нет изменений?\n",
      "  [ctx1] → two option provide empty commit message new commit yet save message si...  (score 0.449)\n",
      "  [ctx2] → stage change tracked file include modification deletion thing also sta...  (score 0.431)\n",
      "  [ctx3] → see answer brian riehman pat notz link question one solution use comma...  (score 0.425)\n",
      "! Ответ Gemini:\n",
      " Я не могу ответить на этот вопрос, используя предоставленные фрагменты знаний.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "515e60edc0d045c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Выводы:\n",
    "- Retrieval резко сокращает галлюцинации, то есть Gemini держится фактов из сниппетов\n",
    "- Ключевой параметр — качество эмбеддингов и ранжирование. Иногда среди top‑3 нет прямого решения и LLM ошибается\n",
    "\n",
    "Ограничения:\n",
    "- Контекстное окно — 32k+ токенов достаточно, но лучше сжимать сниппеты\n",
    "- Бесплатная квота Gemini примерно 50RPS / 1M tokens в месяц\n",
    "\n",
    "Улучшения:\n",
    "1. Увеличить базу знаний\n",
    "2. Добавить больше сниппетов\n",
    "3. Использовать более мощную модель эмбеддингов (например, `all-MiniLM-L12-v2`)\n",
    "4. Использовать более мощную модель LLM (например, `gemini-2.0-advanced`)\n",
    "5. Сделать поиск лучше, возможно эмбеддинг по `CleanTitle` и добавить теги\n"
   ],
   "id": "eddf7830622dd69f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
